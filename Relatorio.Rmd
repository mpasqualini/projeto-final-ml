---
title: "Projeto Final | Aprendizado de Máquina"
author: 
  - LEONARDO DE OLIVEIRA PENNA
  - JEFERSON PEREIRA DE ANDRADE
  - NATHALIA STEFANY SANTOS SILVA
  - MARIANA DE CASTRO PASQUALINI
  - MIGUEL GIOVANE GONZAGA RODRIGUES
date: "09 de dezembro de 2022"
output: 
  pdf_document:
     latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```
# 1. Classificador

## Problema 

Temos um problema de classificação multiclasse. Como cada jogador tem mais de uma classificação considerada correta, uma abordagem possível é utilizando modelos _multilabel_, que pode atribuir um ou mais rótulos não-exclusivos para uma mesma observação. 

Porém, para simplificar o problema, optamos por tratá-lo apenas como um classificador multiclasse, que atribui dentre as N classes disponíveis, um único rótulo. Para não perder a informação de que mais de uma posição pode estar correta, treinamos o modelo no formato longo e para a predição final, agrupamos por jogador a de maior probabilidade.

$Y$ é a variável resposta categórica, com $|\mathcal{C}|=27$, em que estimamos $\mathbb{P}(Y = \mathcal{c}|\mathbf{x})$. Temos uma matriz de covariáveis $\boldsymbol{X}$ com 41 features.

### Função de risco

$$
R(g) :=  \mathbb{E}[\mathbb{I}(Y \neq g(\boldsymbol{X}))] = \mathbb{P}(Y \neq g(\boldsymbol{X}))
$$

Adotamos a função de perda 0-1, comum para problemas de classificação.

### Data splitting 

O conjunto de dados de treino foi separado em treino e validação, para estimar $\hat{R}(g)$. 70% das observações foram para treino e 30% para validação.

## Análise descritiva

Na tabela abaixo, encontram-se as principais estatísticas descritivas das covariáveis dos modelos. 

```{r echo=FALSE}
data_summary <- read_rds("artifacts/summary-stats.RDS")

data_summary |> 
  select(-c(contains("character"), numeric.hist, complete_rate, n_missing)) |> 
  knitr::kable(booktabs= TRUE, digits = .6, col.names = c("Tipo", 
                                                          "Variável",
                                                          "Média", 
                                                          "Desvio-padrão",
                                                          "Mínimo",
                                                          "Q25",
                                                          "Q50",
                                                          "Q75",
                                                          "Máximo"
  ))
```


## Modelos 

Foram treinados 5 modelos distintos:

- Regressão multinomial ou _softmax_
- Naive Bayes
- Support Vector Machines
- Árvores de decisão
- Random Forest

O método que forneceu o melhor resultado foi o Random Forest, de acordo com o risco estimado no conjunto de validação, apresentado na tabela a seguir.

```{r echo=FALSE}

read.csv("artifacts/loss-models.csv") |> 
  mutate(Modelo =
           case_when(
             Modelo == "Y_val_nb" ~ "Naive Bayes",
             Modelo == "Y_val_svm" ~ "SVM",
             Modelo == "Y_val" ~ "Regressão multinomial",
             Modelo == "Y_val_tree" ~ "Árvore de decisão",
             Modelo == "Y_val_rf" ~ "Random Forest"
           )
  ) |> 
  knitr::kable( booktabs = TRUE, col.names = c("Modelo", "Risco estimado"))

```

É importante notar que, comparado aos outros métodos, é possível que o método de menor risco estimado esteja super-ajustando aos dados de validação.

## Redução de dimensionalidade

Aplicamos a técnica de análise de componente principal (PCA) para redução de dimensionalidade das covariáveis numéricas e há claramente um agrupamento nos dados. Observa-se no gráfico abaixo os primeiros dois componentes, com as observações individuais e a correlação entre as variáveis.

![](artifacts/pca-plot.png)


## Comentários

O ponto mais difícil foi fazer o tratamento da variável resposta `Preffered_Position`, quebrando as uma ou mais posições de cada jogador. Fazer uma seleção de variáveis pode ser interessante para melhorar o desempenho dos modelos. Com mais tempo, outro ponto é alterar os _tunning parameters_ de cada modelo e também usar uma outra função de risco, como por exemplo a entropia cruzada para classificação multiclasse. Ainda, é possível explorar outras técnicas e modelos para atribuir mais de uma classe à mesma instância.

# 2. Recomendador